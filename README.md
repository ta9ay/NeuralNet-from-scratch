# NeuralNet-from-scratch
A feed-forward neural network written from scratch. Uses stochastic gradient descent for backpropogation. 
This is a simplified version I wrote for myself to understand how NN's work. Only uses one hidden layer. The sample data is in the file itself. Play with number of hidden layer nodes, learning rate, and epochs. 
